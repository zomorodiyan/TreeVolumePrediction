{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello home!\n",
      "heart_df['result']: 0       0.090\n",
      "1       0.103\n",
      "2       0.114\n",
      "3       0.087\n",
      "4       0.106\n",
      "        ...  \n",
      "194    20.027\n",
      "195    19.468\n",
      "196    18.781\n",
      "197    24.393\n",
      "198    19.391\n",
      "Name: result, Length: 199, dtype: float64\n",
      "y_label: [[ 0.09 ]\n",
      " [ 0.103]\n",
      " [ 0.114]\n",
      " [ 0.087]\n",
      " [ 0.106]\n",
      " [ 0.113]\n",
      " [ 0.138]\n",
      " [ 0.632]\n",
      " [ 0.316]\n",
      " [ 0.279]\n",
      " [ 0.204]\n",
      " [ 0.16 ]\n",
      " [ 0.244]\n",
      " [ 0.188]\n",
      " [ 0.153]\n",
      " [ 0.583]\n",
      " [ 0.619]\n",
      " [ 0.524]\n",
      " [ 0.395]\n",
      " [ 0.583]\n",
      " [ 0.441]\n",
      " [ 0.481]\n",
      " [ 0.426]\n",
      " [ 0.393]\n",
      " [ 0.91 ]\n",
      " [ 0.688]\n",
      " [ 1.287]\n",
      " [ 0.704]\n",
      " [ 0.526]\n",
      " [ 0.797]\n",
      " [ 0.928]\n",
      " [ 0.692]\n",
      " [ 0.675]\n",
      " [ 1.509]\n",
      " [ 1.471]\n",
      " [ 0.907]\n",
      " [ 0.968]\n",
      " [ 1.184]\n",
      " [ 1.312]\n",
      " [ 1.063]\n",
      " [ 1.065]\n",
      " [ 1.45 ]\n",
      " [ 0.931]\n",
      " [ 2.209]\n",
      " [ 2.355]\n",
      " [ 1.201]\n",
      " [ 1.454]\n",
      " [ 1.453]\n",
      " [ 1.611]\n",
      " [ 1.956]\n",
      " [ 1.171]\n",
      " [ 1.158]\n",
      " [ 2.176]\n",
      " [ 1.356]\n",
      " [ 2.109]\n",
      " [ 1.803]\n",
      " [ 2.086]\n",
      " [ 1.41 ]\n",
      " [ 1.795]\n",
      " [ 2.021]\n",
      " [ 1.846]\n",
      " [ 3.64 ]\n",
      " [ 3.958]\n",
      " [ 2.565]\n",
      " [ 2.625]\n",
      " [ 1.014]\n",
      " [ 2.626]\n",
      " [ 3.252]\n",
      " [ 2.436]\n",
      " [ 1.35 ]\n",
      " [ 3.546]\n",
      " [ 3.726]\n",
      " [ 4.194]\n",
      " [ 1.635]\n",
      " [ 4.365]\n",
      " [ 4.561]\n",
      " [ 4.325]\n",
      " [ 3.582]\n",
      " [ 4.209]\n",
      " [ 4.436]\n",
      " [ 5.549]\n",
      " [ 5.096]\n",
      " [ 2.641]\n",
      " [ 4.288]\n",
      " [ 3.725]\n",
      " [ 5.91 ]\n",
      " [ 4.325]\n",
      " [ 4.144]\n",
      " [ 5.854]\n",
      " [ 4.155]\n",
      " [ 5.074]\n",
      " [ 3.814]\n",
      " [ 5.132]\n",
      " [ 4.419]\n",
      " [ 4.78 ]\n",
      " [ 6.182]\n",
      " [ 7.921]\n",
      " [ 5.506]\n",
      " [ 5.27 ]\n",
      " [ 4.432]\n",
      " [ 6.524]\n",
      " [ 6.246]\n",
      " [ 6.963]\n",
      " [ 7.213]\n",
      " [ 7.596]\n",
      " [ 7.964]\n",
      " [ 4.926]\n",
      " [ 6.71 ]\n",
      " [ 6.139]\n",
      " [ 6.742]\n",
      " [ 9.531]\n",
      " [ 6.65 ]\n",
      " [ 8.483]\n",
      " [10.22 ]\n",
      " [ 9.866]\n",
      " [ 9.67 ]\n",
      " [10.739]\n",
      " [ 6.101]\n",
      " [ 6.982]\n",
      " [ 9.574]\n",
      " [ 9.672]\n",
      " [12.015]\n",
      " [ 9.313]\n",
      " [10.952]\n",
      " [ 7.981]\n",
      " [ 8.916]\n",
      " [ 6.341]\n",
      " [ 8.847]\n",
      " [11.116]\n",
      " [10.03 ]\n",
      " [ 9.872]\n",
      " [ 9.553]\n",
      " [13.485]\n",
      " [11.077]\n",
      " [11.744]\n",
      " [ 8.982]\n",
      " [10.151]\n",
      " [13.879]\n",
      " [12.765]\n",
      " [12.76 ]\n",
      " [11.255]\n",
      " [ 9.021]\n",
      " [ 9.387]\n",
      " [14.141]\n",
      " [11.916]\n",
      " [ 7.822]\n",
      " [ 9.96 ]\n",
      " [11.367]\n",
      " [18.01 ]\n",
      " [15.811]\n",
      " [11.043]\n",
      " [16.32 ]\n",
      " [17.839]\n",
      " [19.137]\n",
      " [13.262]\n",
      " [13.324]\n",
      " [16.147]\n",
      " [15.022]\n",
      " [12.513]\n",
      " [17.043]\n",
      " [14.417]\n",
      " [12.619]\n",
      " [14.072]\n",
      " [13.237]\n",
      " [17.937]\n",
      " [16.085]\n",
      " [19.024]\n",
      " [12.934]\n",
      " [20.195]\n",
      " [13.198]\n",
      " [16.28 ]\n",
      " [ 7.827]\n",
      " [13.644]\n",
      " [13.973]\n",
      " [13.267]\n",
      " [17.965]\n",
      " [19.791]\n",
      " [14.428]\n",
      " [14.855]\n",
      " [13.119]\n",
      " [19.651]\n",
      " [16.074]\n",
      " [20.851]\n",
      " [21.941]\n",
      " [17.698]\n",
      " [22.637]\n",
      " [19.538]\n",
      " [25.701]\n",
      " [18.156]\n",
      " [21.059]\n",
      " [16.457]\n",
      " [31.914]\n",
      " [18.407]\n",
      " [14.723]\n",
      " [20.027]\n",
      " [19.468]\n",
      " [18.781]\n",
      " [24.393]\n",
      " [19.391]]\n",
      "ytrain: [[11.255]\n",
      " [16.457]\n",
      " [ 6.65 ]\n",
      " [10.952]\n",
      " [ 6.742]\n",
      " [ 8.982]\n",
      " [ 1.45 ]\n",
      " [ 9.872]\n",
      " [12.76 ]\n",
      " [ 0.113]\n",
      " [ 9.553]\n",
      " [ 6.524]\n",
      " [ 0.16 ]\n",
      " [19.538]\n",
      " [ 0.91 ]\n",
      " [ 4.155]\n",
      " [ 2.626]\n",
      " [ 0.316]\n",
      " [ 7.827]\n",
      " [13.267]\n",
      " [ 0.526]\n",
      " [12.513]\n",
      " [ 4.78 ]\n",
      " [ 0.931]\n",
      " [19.391]\n",
      " [ 2.641]\n",
      " [11.367]\n",
      " [ 4.926]\n",
      " [ 6.139]\n",
      " [ 9.387]\n",
      " [19.024]\n",
      " [16.085]\n",
      " [16.32 ]\n",
      " [ 4.436]\n",
      " [ 0.103]\n",
      " [ 9.574]\n",
      " [31.914]\n",
      " [21.941]\n",
      " [17.043]\n",
      " [25.701]\n",
      " [ 9.96 ]\n",
      " [ 0.968]\n",
      " [19.791]\n",
      " [14.855]\n",
      " [ 3.958]\n",
      " [ 0.09 ]\n",
      " [ 0.704]\n",
      " [16.147]\n",
      " [ 5.27 ]\n",
      " [ 6.982]\n",
      " [ 0.441]\n",
      " [15.022]\n",
      " [13.324]\n",
      " [ 9.021]\n",
      " [ 3.582]\n",
      " [ 0.928]\n",
      " [19.137]\n",
      " [ 0.524]\n",
      " [ 2.021]\n",
      " [19.651]\n",
      " [ 9.866]\n",
      " [ 6.341]\n",
      " [13.879]\n",
      " [12.619]\n",
      " [ 4.419]\n",
      " [15.811]\n",
      " [ 0.481]\n",
      " [ 1.803]\n",
      " [ 0.619]\n",
      " [11.916]\n",
      " [ 3.814]\n",
      " [ 4.432]\n",
      " [ 9.672]\n",
      " [18.781]\n",
      " [ 4.365]\n",
      " [13.198]\n",
      " [14.417]\n",
      " [14.141]\n",
      " [19.468]\n",
      " [ 4.144]\n",
      " [ 5.074]\n",
      " [ 3.725]\n",
      " [ 0.395]\n",
      " [ 5.506]\n",
      " [ 6.246]\n",
      " [13.237]\n",
      " [11.744]\n",
      " [ 3.64 ]\n",
      " [ 5.096]\n",
      " [ 2.436]\n",
      " [10.03 ]\n",
      " [ 2.086]\n",
      " [ 0.583]\n",
      " [ 4.325]\n",
      " [ 3.546]\n",
      " [ 1.846]\n",
      " [ 1.471]\n",
      " [ 1.065]\n",
      " [12.765]\n",
      " [ 4.325]\n",
      " [17.839]\n",
      " [ 1.287]\n",
      " [ 0.675]\n",
      " [20.027]\n",
      " [ 7.921]\n",
      " [ 4.288]\n",
      " [ 9.531]\n",
      " [ 7.964]\n",
      " [ 1.635]\n",
      " [ 6.101]\n",
      " [11.043]\n",
      " [ 7.822]\n",
      " [13.262]\n",
      " [24.393]\n",
      " [10.151]\n",
      " [ 1.063]\n",
      " [ 1.956]\n",
      " [22.637]\n",
      " [13.485]\n",
      " [ 1.171]\n",
      " [ 2.176]\n",
      " [ 5.549]\n",
      " [17.698]\n",
      " [12.015]\n",
      " [18.156]\n",
      " [ 1.454]\n",
      " [ 5.854]\n",
      " [ 1.35 ]\n",
      " [ 3.252]\n",
      " [20.851]\n",
      " [ 1.795]\n",
      " [ 1.509]\n",
      " [ 1.312]\n",
      " [ 7.213]\n",
      " [ 1.158]\n",
      " [ 6.71 ]\n",
      " [16.28 ]\n",
      " [ 0.106]\n",
      " [ 6.963]\n",
      " [12.934]\n",
      " [ 1.184]\n",
      " [10.739]\n",
      " [ 7.981]\n",
      " [18.01 ]\n",
      " [ 0.692]\n",
      " [ 2.565]\n",
      " [ 1.453]\n",
      " [14.723]\n",
      " [ 6.182]\n",
      " [14.428]\n",
      " [14.072]\n",
      " [ 0.632]\n",
      " [ 7.596]\n",
      " [ 4.561]\n",
      " [ 2.209]\n",
      " [ 0.426]\n",
      " [ 4.194]\n",
      " [ 0.583]\n",
      " [20.195]]\n",
      "Xtrain is: [[0.71428571 0.71320093 0.72886297 0.63173217]\n",
      " [0.42857143 0.90712617 0.69970845 0.69868996]\n",
      " [0.57142857 0.54439252 0.63265306 0.42503639]\n",
      " [0.78571429 0.5911215  0.86588921 0.51382824]\n",
      " [0.5        0.51693925 0.76093294 0.430131  ]\n",
      " [0.21428571 0.64310748 0.77842566 0.5705968 ]\n",
      " [0.28571429 0.21670561 0.59183673 0.14628821]\n",
      " [0.28571429 0.64369159 0.84548105 0.49053857]\n",
      " [0.57142857 0.71962617 0.70845481 0.60334789]\n",
      " [0.42857143 0.00876168 0.02040816 0.00727802]\n",
      " [0.5        0.65683411 0.73760933 0.54876274]\n",
      " [0.85714286 0.53212617 0.51020408 0.5705968 ]\n",
      " [0.5        0.0385514  0.16909621 0.01382824]\n",
      " [0.57142857 0.91471963 0.81632653 0.84279476]\n",
      " [0.42857143 0.16764019 0.3148688  0.13755459]\n",
      " [0.57142857 0.41004673 0.6851312  0.34570597]\n",
      " [0.57142857 0.33119159 0.41107872 0.31004367]\n",
      " [0.42857143 0.05841121 0.22157434 0.05021834]\n",
      " [0.42857143 0.81658879 0.80466472 0.82678311]\n",
      " [0.71428571 0.88025701 0.67638484 0.51164483]\n",
      " [0.35714286 0.1442757  0.11661808 0.17030568]\n",
      " [0.57142857 0.78037383 0.60349854 0.70887918]\n",
      " [0.64285714 0.45969626 0.49854227 0.356623  ]\n",
      " [0.21428571 0.19976636 0.40233236 0.1426492 ]\n",
      " [0.64285714 0.95502336 0.52478134 0.52547307]\n",
      " [0.64285714 0.44042056 0.3819242  0.19650655]\n",
      " [0.71428571 0.72254673 0.47521866 0.54294032]\n",
      " [0.64285714 0.50175234 0.3819242  0.57350801]\n",
      " [0.92857143 0.50175234 0.79300292 0.48326055]\n",
      " [0.64285714 0.6875     0.73760933 0.41048035]\n",
      " [0.57142857 0.80724299 0.71428571 0.41775837]\n",
      " [0.42857143 0.85630841 0.90087464 0.70160116]\n",
      " [0.         0.72196262 0.84548105 0.37554585]\n",
      " [0.5        0.39369159 0.60641399 0.36535662]\n",
      " [0.57142857 0.01285047 0.12827988 0.00509461]\n",
      " [0.42857143 0.62324766 0.6909621  0.38719068]\n",
      " [0.42857143 1.         0.75801749 1.        ]\n",
      " [0.64285714 0.90946262 0.7638484  0.70887918]\n",
      " [0.5        0.81191589 0.66180758 0.61426492]\n",
      " [0.5        0.94450935 0.75801749 0.6797671 ]\n",
      " [0.78571429 0.69801402 0.45189504 0.35443959]\n",
      " [0.57142857 0.18224299 0.31195335 0.05021834]\n",
      " [0.57142857 0.88609813 0.90670554 0.7874818 ]\n",
      " [0.57142857 0.88317757 0.70845481 0.73071325]\n",
      " [0.28571429 0.35397196 0.73469388 0.2860262 ]\n",
      " [0.64285714 0.         0.06705539 0.        ]\n",
      " [0.57142857 0.16179907 0.39067055 0.1069869 ]\n",
      " [0.5        0.78329439 1.         0.66885007]\n",
      " [0.57142857 0.48831776 0.58892128 0.44468705]\n",
      " [0.5        0.55607477 0.55393586 0.41921397]\n",
      " [0.64285714 0.10630841 0.25364431 0.07423581]\n",
      " [0.5        0.78679907 0.66180758 0.50873362]\n",
      " [0.42857143 0.75292056 0.65889213 0.69650655]\n",
      " [0.5        0.67873832 0.51603499 0.57787482]\n",
      " [0.64285714 0.38434579 0.66472303 0.33114993]\n",
      " [0.71428571 0.16939252 0.40524781 0.14046579]\n",
      " [0.57142857 0.74883178 0.95918367 0.73071325]\n",
      " [0.42857143 0.09345794 0.32653061 0.09243086]\n",
      " [0.71428571 0.29906542 0.49854227 0.23653566]\n",
      " [0.71428571 0.86974299 0.86297376 0.83478894]\n",
      " [0.57142857 0.55023364 0.69970845 0.55240175]\n",
      " [0.57142857 0.60630841 0.33819242 0.44905386]\n",
      " [0.71428571 0.71728972 0.78425656 0.61935953]\n",
      " [0.42857143 0.78971963 0.72303207 0.51965066]\n",
      " [0.5        0.48598131 0.43731778 0.3580786 ]\n",
      " [0.5        0.72371495 0.80174927 0.4286754 ]\n",
      " [0.5        0.11799065 0.20699708 0.07933042]\n",
      " [0.5        0.27570093 0.58309038 0.21033479]\n",
      " [0.42857143 0.11799065 0.35860058 0.11208151]\n",
      " [0.57142857 0.68165888 0.89212828 0.51965066]\n",
      " [0.21428571 0.45502336 0.68221574 0.30858806]\n",
      " [0.35714286 0.48247664 0.49271137 0.39956332]\n",
      " [0.78571429 0.59404206 0.63556851 0.54002911]\n",
      " [0.42857143 0.95794393 0.69970845 0.72343523]\n",
      " [0.42857143 0.3942757  0.58017493 0.34716157]\n",
      " [0.42857143 0.82359813 0.55102041 0.62518195]\n",
      " [0.42857143 0.80315421 0.73469388 0.72707424]\n",
      " [0.71428571 0.71962617 0.85714286 0.51419214]\n",
      " [0.42857143 0.9853972  0.72011662 0.36681223]\n",
      " [0.42857143 0.41413551 0.58017493 0.26637555]\n",
      " [0.57142857 0.49766355 0.55685131 0.33988355]\n",
      " [0.35714286 0.40712617 0.52478134 0.34279476]\n",
      " [0.35714286 0.09053738 0.14868805 0.04657933]\n",
      " [0.64285714 0.45735981 0.63265306 0.39810771]\n",
      " [0.92857143 0.52686916 0.54810496 0.54803493]\n",
      " [0.64285714 0.77161215 0.79883382 0.66157205]\n",
      " [0.64285714 0.64953271 0.67930029 0.69505095]\n",
      " [0.57142857 0.34521028 0.6851312  0.32532751]\n",
      " [0.42857143 0.41296729 0.60932945 0.40320233]\n",
      " [0.42857143 0.32651869 0.40816327 0.2852984 ]\n",
      " [0.71428571 0.74591121 0.78717201 0.48326055]\n",
      " [0.5        0.27219626 0.55393586 0.18995633]\n",
      " [0.42857143 0.12091121 0.29737609 0.06914119]\n",
      " [0.71428571 0.43341121 0.51895044 0.26491994]\n",
      " [0.35714286 0.36915888 0.65889213 0.29694323]\n",
      " [0.35714286 0.27628505 0.49562682 0.23944687]\n",
      " [0.5        0.21436916 0.56559767 0.18122271]\n",
      " [0.5        0.18516355 0.41982507 0.09388646]\n",
      " [0.92857143 0.70502336 0.60932945 0.56331878]\n",
      " [0.35714286 0.37792056 0.49854227 0.3224163 ]\n",
      " [0.5        0.74591121 0.78425656 0.79839884]\n",
      " [0.42857143 0.16939252 0.44023324 0.15574964]\n",
      " [0.42857143 0.16179907 0.27113703 0.1069869 ]\n",
      " [0.5        0.98948598 0.66472303 0.71615721]\n",
      " [0.57142857 0.47721963 0.60932945 0.48689956]\n",
      " [0.57142857 0.4182243  0.6122449  0.21688501]\n",
      " [0.42857143 0.54672897 0.70845481 0.55967977]\n",
      " [0.5        0.53271028 0.72303207 0.39956332]\n",
      " [0.5        0.375      0.44897959 0.08660844]\n",
      " [0.57142857 0.55607477 0.45772595 0.25909753]\n",
      " [0.57142857 0.72955607 0.7696793  0.57787482]\n",
      " [0.78571429 0.7161215  0.48104956 0.45924309]\n",
      " [0.42857143 0.75934579 0.77842566 0.40538574]\n",
      " [0.42857143 0.96436916 0.84548105 0.643377  ]\n",
      " [0.57142857 0.65186916 0.75510204 0.53056769]\n",
      " [0.42857143 0.18049065 0.40816327 0.143377  ]\n",
      " [0.51428571 0.25700935 0.49854227 0.22052402]\n",
      " [0.42857143 0.9182243  0.79008746 0.61426492]\n",
      " [0.5        0.64369159 0.88046647 0.70887918]\n",
      " [0.64285714 0.2213785  0.34693878 0.19359534]\n",
      " [0.57142857 0.27219626 0.44023324 0.22852984]\n",
      " [0.78571429 0.42990654 0.75510204 0.38500728]\n",
      " [0.42857143 0.93633178 0.72886297 0.46652111]\n",
      " [0.57142857 0.60134346 0.96209913 0.55312955]\n",
      " [0.57142857 0.91063084 0.79008746 0.59970888]\n",
      " [0.85714286 0.23714953 0.41107872 0.18413392]\n",
      " [0.42857143 0.43691589 0.76093294 0.41193595]\n",
      " [0.71428571 0.33586449 0.2303207  0.1426492 ]\n",
      " [0.42857143 0.34871495 0.7638484  0.29403202]\n",
      " [0.5        0.92990654 0.64431487 0.7852984 ]\n",
      " [0.71428571 0.28738318 0.34985423 0.19723435]\n",
      " [0.42857143 0.18808411 0.51603499 0.18486172]\n",
      " [0.71428571 0.20969626 0.6180758  0.15211063]\n",
      " [0.64285714 0.52219626 0.74052478 0.50873362]\n",
      " [0.5        0.25408879 0.29154519 0.18049491]\n",
      " [0.71428571 0.51285047 0.57725948 0.37772926]\n",
      " [0.42857143 0.82476636 0.81341108 0.69505095]\n",
      " [0.28571429 0.01109813 0.         0.02110626]\n",
      " [0.42857143 0.49766355 0.77259475 0.3944687 ]\n",
      " [0.42857143 0.8317757  0.74927114 0.61062591]\n",
      " [0.57142857 0.20268692 0.52769679 0.14847162]\n",
      " [0.35714286 0.56045561 0.79008746 0.57933042]\n",
      " [0.71428571 0.60981308 0.63848397 0.5371179 ]\n",
      " [0.42857143 0.73714953 0.72011662 0.78165939]\n",
      " [0.35714286 0.1588785  0.14577259 0.143377  ]\n",
      " [1.         0.33119159 0.4664723  0.11935953]\n",
      " [0.64285714 0.22897196 0.41982507 0.23362445]\n",
      " [0.5        0.99415888 0.65306122 0.4985444 ]\n",
      " [0.64285714 0.46436916 0.59183673 0.48180495]\n",
      " [0.57142857 0.88376168 0.75510204 0.67612809]\n",
      " [0.64285714 0.77511682 0.81632653 0.356623  ]\n",
      " [0.42857143 0.07184579 0.29737609 0.06040757]\n",
      " [0.28571429 0.51518692 0.77842566 0.37045124]\n",
      " [0.35714286 0.38785047 0.36443149 0.39010189]\n",
      " [0.42857143 0.25233645 0.59475219 0.24308588]\n",
      " [0.42857143 0.11565421 0.26530612 0.07423581]\n",
      " [0.92857143 0.38084112 0.79591837 0.33770015]\n",
      " [0.28571429 0.1103972  0.41107872 0.08078603]\n",
      " [0.64285714 0.84521028 0.77842566 0.63609898]]\n",
      "Shape of train set is (159, 4)\n",
      "Shape of test set is (40, 4)\n",
      "Shape of train label is (159, 1)\n",
      "Shape of test labels is (40, 1)\n"
     ]
    }
   ],
   "source": [
    "#prepare data downloaded from UCL\n",
    "import tensorflow as tf\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #suppress warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from tensorflow import lite\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"hello home!\")\n",
    "# add header names\n",
    "headers =  ['shib',\"ertefaae_sine\",\n",
    "        'ertefaae_kol','mohit_dar_nim_metr', 'result']\n",
    "heart_df = pd.read_excel('trees.xlsx',sheet_name='Vol_Zaraieb_1', usecols=headers)\n",
    "\n",
    "#convert imput to numpy arrays\n",
    "X = heart_df.drop(columns=['result'])\n",
    "\n",
    "y_label = heart_df['result'].values.reshape(X.shape[0], 1)\n",
    "print(\"heart_df['result']: {}\".format(heart_df['result'], '2.4f'))\n",
    "print(\"y_label: {}\".format(y_label, '2.4f'))\n",
    "\n",
    "\n",
    "#split data into train and test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y_label, test_size=0.2, random_state=2)\n",
    "print(\"ytrain: {}\".format(ytrain, '2.4f'))\n",
    "\n",
    "originalResults = copy.deepcopy(ytrain);\n",
    "#standardize the dataset\n",
    "scX = preprocessing.MinMaxScaler()\n",
    "scX.fit(Xtrain)\n",
    "Xtrain = scX.transform(Xtrain)\n",
    "Xtest = scX.transform(Xtest)\n",
    "print(f\"Xtrain is: {Xtrain}\")\n",
    "\n",
    "scY = preprocessing.MinMaxScaler()\n",
    "scY.fit(ytrain)\n",
    "\n",
    "# ytrain = scY.transform(ytrain)\n",
    "ytest = scY.transform(ytest)\n",
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_shape=(4,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy','mse'])\n",
    "\n",
    "hist = model.fit(Xtrain, ytrain, epochs=400, verbose=0,shuffle=True, validation_split=0.1, batch_size=50)\n",
    "\n",
    "\n",
    "\n",
    "# train_pred = model.predict(Xtrain)\n",
    "# test_pred = model.predict(Xtest)\n",
    "# print(\"Train accuracy of keras neural network: {}\".format(mean_squared_error(train_pred, ytrain)))\n",
    "# print(\"Test accuracy of keras neural network: {}\".format(mean_squared_error(test_pred, ytest)))\n",
    "# print(\"\\n\")\n",
    "# print(heart_df.head())\n",
    "\n",
    "# plt.scatter(test_pred, ytest)\n",
    "\n",
    "# keras_file='cf.h5'\n",
    "# models.save_model(model,keras_file)\n",
    "# converter=tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "# tfmodel = converter.convert()\n",
    "# open(\"degree.tflite\",\"wb\").write(tfmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled results are: [[0.9679334]\n",
      " [0.9659668]\n",
      " [0.9530083]\n",
      " [0.9503957]\n",
      " [0.9953752]]\n",
      "min is: 0.09\n",
      "max is: 31.914\n",
      "Manual Reverse scaled predicted results are: [[30.893513]\n",
      " [30.830927]\n",
      " [30.418535]\n",
      " [30.335392]\n",
      " [31.76682 ]]\n",
      "inverse_transform results are: [[30.893513]\n",
      " [30.830929]\n",
      " [30.418535]\n",
      " [30.335394]\n",
      " [31.76682 ]]\n",
      "expected (original) results are: [0.09, 0.103, 0.114, 0.087, 19.391]\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 19\n",
      "Trainable params: 19\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# sc = preprocessing.MinMaxScaler()\n",
    "sampleInput = [[45,436,15.3,252],[40,480,17.4,266],[30,504,15.8,266],[30,480,14.2,260],[45,3706,31,1696]];\n",
    "# sc.fit(sampleInput)\n",
    "sampleInput = scX.transform(sampleInput)\n",
    "sampleInputResult = model.predict(sampleInput)\n",
    "\n",
    "# scRev = preprocessing.MinMaxScaler()\n",
    "# scRev.fit(originalResults)\n",
    "\n",
    "def reverseMinMaxScale(data, originalData):\n",
    "    reversedData = copy.deepcopy(data)\n",
    "    min = originalData.min()\n",
    "    max = originalData.max()\n",
    "    print(f\"min is: {min}\")\n",
    "    print(f\"max is: {max}\")\n",
    "    index = 0;\n",
    "    for item in reversedData: \n",
    "        reversedData[index] = (item * (max - min)) + min\n",
    "        index+=1\n",
    "    return reversedData;\n",
    "        \n",
    "\n",
    "print(\"Scaled results are: {}\".format(sampleInputResult, '2.4f'))\n",
    "print(\"Manual Reverse scaled predicted results are: {}\".format(reverseMinMaxScale(sampleInputResult, originalResults), '2.4f'))\n",
    "print(\"inverse_transform results are: {}\".format(scY.inverse_transform(sampleInputResult), '2.4f'))\n",
    "\n",
    "\n",
    "print(\"expected (original) results are: {}\".format([0.090,0.103,0.114,0.087,19.391], '2.4f'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_pred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_pred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(ytrain), np.min(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9819566a768b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-781818ef403c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(hist.history['mse'], c='red')\n",
    "plt.plot(hist.history['val_mse'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
